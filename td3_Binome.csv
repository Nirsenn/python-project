"id"	"texte"	"origine"
"1"	"Please post your personal projects, startups, product placements, collaboration needs, blogs etc.  Please mention the payment and pricing requirements for products and services.  Please do not post link shorteners, link aggregator websites , or auto-subscribe links.  \--  Any abuse of trust will lead to bans.  Encourage others who create new posts for questions to post here instead!  Thread will stay alive until next one so keep posting after the date in the title.  \--  Meta: This is an experiment. If the community doesnt like this, we will cancel it. This is to encourage those in the community to promote their work by not spamming the main threads."	"reddit"
"2"	"**For Job Postings** please use this template  >Hiring: \[Location\], Salary:\[\], \[Remote | Relocation\], \[Full Time | Contract | Part Time\]    and \[Brief overview, what you're looking for\]  **For Those looking for jobs** please use this template  >Want to be Hired: \[Location\], Salary Expectation:\[\], \[Remote | Relocation\], \[Full Time | Contract | Part Time\]  Resume: \[Link to resume\] and \[Brief overview, what you're looking for\]     Please remember that this community is geared towards those with experience."	"reddit"
"3"	"I'm a reviewer (PC) and don’t have a submission myself, but honestly, this is the weirdest reviewing process I’ve ever experienced.      1. Phase 2 papers are worse than Phase 1.    In Phase 1, I reviewed four papers and gave scores of 3, 4, 5, and 5. I was even open to raising the scores after the discussion, but all of them ended up being rejected. Now, in Phase 2, I have papers rated 3 and 4, but they’re noticeably weaker than the ones from Phase 1.  2. It feels like one reviewer is personally connected to a paper.   I gave a score of 3 because the paper lacked technical details, justifications, and clear explanations for inconsistencies in conventions. My review was quite detailed—thousands of characters long—and I even wrote another long response after the rebuttal. Meanwhile, another reviewer gave an initial rating of 7 (confidence 5) with a very short review, and later tried to defend the paper and raise the score to 8. That reviewer even wrote, *“The authors have clearly addressed most of the reviewers' concerns. Some experimental questions were not addressed due to regulatory requirements.”* But I never raised any experimental questions, and none of my concerns were actually resolved.  \+ actually this paper's performance looks very good, but 'paper' is just not about performance.     Should I report this somewhere? If this paper is accepted, I'll be very disappointed and will never submit or review a paper from AAAI. There are tons of better paper."	"reddit"
"4"	"Hi everyone,  I’ve noticed that most discussions lately revolve around LLMs and NLP, but I’m curious about what other areas in AI/ML are currently getting attention in research.  What topics or fields do you think are becoming exciting right now?"	"reddit"
"5"	"I've figured out the error that was published several years ago. The paper provides a convergence theorem of fundamental algorithm. The key theorem relies on the specific Lemma, however, I figured out that invoking this lemma is a ""bit"" misleading. They should add a bit stronger assumption (which, I do not think it is that strong) to invoke such lemma.   However, due to this issue, the key theorem does collapse.  What should I do?"	"reddit"
"6"	"We implemented Stanford's recent ""Agentic Context Engineering"" paper (https://arxiv.org/abs/2510.04618) and open-sourced it.   Instead of fine-tuning, agents curate their own context by learning from execution feedback. Three-agent system (Generator, Reflector, Curator) builds a ""playbook"" of strategies autonomously.   GitHub: https://github.com/kayba-ai/agentic-context-engine   Interested in feedback from the community on the approach and implementation!"	"reddit"
"7"	"i have the option to take a numerical analysis class next semester, and I wanted to ask, what are some cool applications of machine learning and deep learning with numerical analysis? And what jobs combine ML and numerical analysis techniques?"	"reddit"
"8"	"Hi everyone,  I'm starting a project to train a reinforcement learning agent that can operate a desktop computer, with the eventual goal of performing multi-step tasks. I have a good grasp of RL theory but I'm hitting a wall trying to find a suitable environment to actually train and benchmark my agent.  I'm looking for something that mimics a real desktop interaction, but in a controlled setting. Here’s a breakdown of what I need:  **1. Observation Space:**   The observation should be a representation of the current screen state. I'm open to different approaches:  * **Pixel-based:** A screenshot of the desktop/virtual machine. This is the most general form. * **DOM/HTML-based:** If the environment is web-focused, the HTML source code of the current page would be a fantastic, more structured alternative to pixels. * **Accessibility Tree:** Something like the UI hierarchy from Windows' UI Automation or Apple's Accessibility APIs would also be great.  **2. Action Space:**   The agent needs to perform low-level actions, similar to a human user:  * **Mouse:** Move to (x, y) coordinates, left/right/middle click, click-and-drag, scroll. * **Keyboard:** Send keystrokes (both text and special keys like `ENTER`, `TAB`).  **3. The Crucial Part: A Benchmark Suite**   This is where I'm really struggling. I don't just need an empty environment  I need a **curated set of tasks** to define success and measure progress. Ideally, this would be a suite of tasks with a clear reward signal.  **Example tasks I have in mind:**  * **Web Tasks:**    * ""Log into Gmail.""    * ""Search for a product on Amazon and add it to your cart.""    * ""Find the contact email on a company's 'About Us' page."" * **Desktop Application Tasks:**    * ""Open a text editor, write a sentence, and save the file to the desktop.""    * ""Create a new calendar event for tomorrow at 3 PM.""  I've looked at environments like `miniwob++`, which is a great start and almost exactly what I need for web tasks, but I'm wondering if there's anything more robust, more modern, or that extends beyond the browser to the full desktop OS.  **My Questions:**  1. Does a ready-to-use environment like this already exist? (e.g., a ""DesktopGym"" or ""WebShoppingSuite-v0""?) 2. If not, what would be the best way to build one? Is it better to create a virtual machine and use image-based observations, or is there a framework for hooking into a browser/OS to get a more structured observation space? 3. Are there any known research projects or benchmarks that have tackled this specific problem of a general desktop agent?  Any pointers to papers, GitHub repos, or existing projects would be immensely appreciated. Thanks in advance"	"reddit"
"9"	"I built and trained this very simple MoE \[ [Beens-MiniMax](https://github.com/Abinesh-Mathivanan/beens-minimax) \] from scratch in a span of 5 days. You could read more in the [report](https://github.com/Abinesh-Mathivanan/beens-minimax/blob/main/Beens_MiniMax__How_not_to_Build_an_LLM.pdf) here."	"reddit"
"10"	"We’re releasing **Kanops Open Access · Imagery (Retail Scenes v0)**: \~10k+ retail photos (UK/US supermarkets  fixtures, shippers, pumpkins/seasonal, signage).   Faces are blurred    EXIF/IPTC carries provenance.   Dataset is **gated for evaluation use** (no redistribution/model-weight redistribution).  * HF dataset: [https://huggingface.co/datasets/dresserman/kanops-open-access-imagery](https://huggingface.co/datasets/dresserman/kanops-open-access-imagery) * Structure: train/{2014, FullStores, Halloween2024}/Retailer/Subcategory/\*.jpeg * Files: MANIFEST.csv, metadata.csv, checksums.sha256, LICENSE, [README.md](http://README.md)  **Intended tasks:** scene understanding for retail (bay detection, planogram reasoning, signage classification, seasonal, OCR-on-shelves plus other use cases around retail shelf fill and other use cases......   **Quick load (imagefolder):**  **# pip install datasets**  **from datasets import load\_dataset**  **ds = load\_dataset(""imagefolder"", data\_dir=""hf://datasets/dresserman/kanops-open-access-imagery/train"")**  **print(len(ds\[""train""\]))**  **Roadmap (v1):** add weak labels (orientation, aspect, season) and CVAT tags.  **Contact:** [happytohelp@groceryinsight.com](mailto:happytohelp@groceryinsight.com)  Happy to answer questions + consider task suggestions."	"reddit"
"11"	"Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley."	"arxiv"
"12"	"I describe an optimal control view of adversarial machine learning, where the dynamical system is the machine learner, the input are adversarial actions, and the control costs are defined by the adversary's goals to do harm and be hard to detect. This view encompasses many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping. The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning."	"arxiv"
"13"	"The article is devoted to the problem of small learning samples in machine learning. The flaws of maximum likelihood learning and minimax learning are looked into and the concept of minimax deviation learning is introduced that is free of those flaws."	"arxiv"
"14"	"In this chapter, we provide a brief overview of applying machine learning techniques for clinical prediction tasks. We begin with a quick introduction to the concepts of machine learning and outline some of the most common machine learning algorithms. Next, we demonstrate how to apply the algorithms with appropriate toolkits to conduct machine learning experiments for clinical prediction tasks. The objectives of this chapter are to (1) understand the basics of machine learning techniques and the reasons behind why they are useful for solving clinical prediction problems, (2) understand the intuition behind some machine learning models, including regression, decision trees, and support vector machines, and (3) understand how to apply these models to clinical prediction problems using publicly available datasets via case studies."	"arxiv"
"15"	"Machine learning technologies have demonstrated immense capabilities in various domains. They play a key role in the success of modern businesses. However, adoption of machine learning technologies has a lot of untouched potential. Cost of developing custom machine learning solutions that solve unique business problems is a major inhibitor to far-reaching adoption of machine learning technologies. We recognize that the monolithic nature prevalent in today's machine learning applications stands in the way of efficient and cost effective customized machine learning solution development. In this work we explore the benefits of modular machine learning solutions and discuss how modular machine learning solutions can overcome some of the major solution engineering limitations of monolithic machine learning solutions. We analyze the trade-offs between modular and monolithic machine learning solutions through three deep learning problems; one text based and the two image based. Our experimental results show that modular machine learning solutions have a promising potential to reap the solution engineering advantages of modularity while gaining performance and data advantages in a way the monolithic machine learning solutions do not permit."	"arxiv"
"16"	"Introduction to Machine learning covering Statistical Inference (Bayes, EM, ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering), and PAC learning (the Formal model, VC dimension, Double Sampling theorem)."	"arxiv"
"17"	"Machine learning techniques have influenced the field of computer architecture like many other fields. This paper studies how the fundamental machine learning techniques can be applied towards computer architecture problems. We also provide a detailed survey of computer architecture research that employs different machine learning methods. Finally, we present some future opportunities and the outstanding challenges that need to be overcome to exploit full potential of machine learning for computer architecture."	"arxiv"
"18"	"Recently, the use of machine learning in meteorology has increased greatly. While many machine learning methods are not new, university classes on machine learning are largely unavailable to meteorology students and are not required to become a meteorologist. The lack of formal instruction has contributed to perception that machine learning methods are 'black boxes' and thus end-users are hesitant to apply the machine learning methods in their every day workflow. To reduce the opaqueness of machine learning methods and lower hesitancy towards machine learning in meteorology, this paper provides a survey of some of the most common machine learning methods. A familiar meteorological example is used to contextualize the machine learning methods while also discussing machine learning topics using plain language. The following machine learning methods are demonstrated: linear regression; logistic regression; decision trees; random forest; gradient boosted decision trees; naive Bayes; and support vector machines. Beyond discussing the different methods, the paper also contains discussions on the general machine learning process as well as best practices to enable readers to apply machine learning to their own datasets. Furthermore, all code (in the form of Jupyter notebooks and Google Colaboratory notebooks) used to make the examples in the paper is provided in an effort to catalyse the use of machine learning in meteorology."	"arxiv"
"19"	"Bias is known to be an impediment to fair decisions in many domains such as human resources, the public sector, health care etc. Recently, hope has been expressed that the use of machine learning methods for taking such decisions would diminish or even resolve the problem. At the same time, machine learning experts warn that machine learning models can be biased as well. In this article, our goal is to explain the issue of bias in machine learning from a technical perspective and to illustrate the impact that biased data can have on a machine learning model. To reach such a goal, we develop interactive plots to visualizing the bias learned from synthetic data."	"arxiv"
"20"	"Transparent machine learning is introduced as an alternative form of machine learning, where both the model and the learning system are represented in source code form. The goal of this project is to enable direct human understanding of machine learning models, giving us the ability to learn, verify, and refine them as programs. If solved, this technology could represent a best-case scenario for the safety and security of AI systems going forward."	"arxiv"
